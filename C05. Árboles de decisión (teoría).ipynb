{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión\n",
    "\n",
    "Todos hemos visto ejemplos de árboles de decisión:\n",
    "\n",
    "<img src=\"ml53.png\">\n",
    "\n",
    "## Partes\n",
    "\n",
    "<img src=\"ml54.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo generamos árboles de decisión? \n",
    "\n",
    "Los árboles de decisión son algoritmos inductivos. Es decir, aprende patrones directamente de ejemplos. \n",
    "\n",
    "Algunos de los algoritmos mas usuales son:\n",
    "\n",
    "* Hunt, en el cual se basan los siguientes.\n",
    "\n",
    "* CART\n",
    "\n",
    "* ID3\n",
    "\n",
    "* C4.5\n",
    "\n",
    "* SliQ y SPRINT para tablas muy grandes\n",
    "\n",
    "## Algoritmo de Hunt\n",
    "\n",
    "Es un algoritmo inductivo, recursivo y oportunista que busca un mínimo local:\n",
    "\n",
    "* **Inductivo.** Se genera directamente basado en ejemplos.\n",
    "\n",
    "* **Recursivo.** Repite el proceso varias veces.\n",
    "\n",
    "* **Oportunista.** En cada paso toma la decisión mas favorable sin pensar en pasos anteriores o futuros.\n",
    "\n",
    "La solución encuentra una solución óptima (minimiza el error) localmente. \n",
    "\n",
    "Funciona partiendo los datos de entrenamiento en grupos cada vez mas pequeños.\n",
    "\n",
    "Para un nodo **T** que tiene un conjunto de elementos **D_T**:\n",
    "\n",
    "- Si todos los elementos de **T** son de la misma clase, dicho nodo es una hoja de esa clase. \n",
    "- Si no lo son, se aplica un criterio **S** que parte **D_T** en subgrupos. Para cada salida del criterio de partición se crea un nodo *hijo* de **T** y los elementos de **D_T** se reparten entre estos nodos hijos.\n",
    "- Repetimos el proceso para cada nodo hijo.\n",
    "\n",
    "Hay varias maneras de de partir un conjunto de elementos en un nodo. El objetivo general en cada paso es maximizar la **pureza** (una partición es 100% pura si todos los elementos en cada subnodo son de la misma clase).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vivienda|Estado civil|Salario|Impago\n",
    ":--:|:--:|:--:|:--:\n",
    "Sí|Soltero|125|No\n",
    "No|Casado|100|No\n",
    "No|Soltero|70|No\n",
    "Sí|Casado|120|No\n",
    "No|Divorciado|95|Sí\n",
    "No|Casado|60|No\n",
    "Sí|Divorciado|220|No\n",
    "No|Soltero|85|Sí\n",
    "No|Casado|75|No\n",
    "No|Soltero|90|Sí\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ml55.png\">\n",
    "<img src=\"ml56.png\">\n",
    "<img src=\"ml57.png\">\n",
    "<img src=\"ml58.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterio de partición\n",
    "\n",
    "Un criterio de partición de una generación de árboles debe responder a las siguientes preguntas:\n",
    "* **¿Cómo separamos los elementos en cada paso?**\n",
    "* **¿Cuándo dejamos de separar elementos?** En teoría podríamos seguir separando hasta que la pureza de cada hoja fuera 1, pero en la práctica esto genera árboles muy complejos y sobreajustados (pues llegaría a memorizar cada observación en una hoja distinta).\n",
    "\n",
    "Para un nodo en concreto, el algoritmo prueba, para cada variable, todas las combinaciones posibles. Hay muchas maneras de hacer particiones.\n",
    "\n",
    "<img src=\"ml59.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué partición elegimos?\n",
    "\n",
    "Elegiremos aquella que maximice la pureza respecto del nodo padre. A este criterio se le llama **ganancia de información (information gain)**. Para calcularla, usamos alguna de las siguientes mediciones de pureza:\n",
    "\n",
    "$$Entropy(t)=-\\sum_{i=0}^{c-1}p(i|t)\\log_2p(i|t)$$\n",
    "$$Gini(t)=1-\\sum_{i=0}^{c-1}p(i|t)^2$$\n",
    "$$Clasification\\,error(t)=1-\\max_{i}p(i|t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo con entropía**\n",
    "\n",
    "Calculamos la entropía de la raíz\n",
    "<img src=\"ml55.png\">\n",
    "<img src=\"ml60.png\">\n",
    "\n",
    "Para cada posible nodo hijo, calculamos la entropía de dicho nodo. \n",
    "\n",
    "Por ejemplo, probamos primero para **Vivienda en propiedad**:\n",
    "<img src=\"ml61.png\">\n",
    "\n",
    "Ahora probamos para **Estado civil**:\n",
    "<img src=\"ml62.png\">\n",
    "\n",
    "E incluso podemos tomar estado civil con otra parición:\n",
    "<img src=\"ml63.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cuándo paramos de crear particiones?\n",
    "\n",
    "<img src=\"ml64.png\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo CART\n",
    "\n",
    "<img src=\"ml91.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
